import math
import time
import re
import undetected_chromedriver as uc
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import UnexpectedAlertPresentException, NoSuchElementException
from openpyxl import Workbook
from selenium.webdriver.chrome.service import Service as ChromeService
from contextlib import contextmanager
import atexit

# ì „ì—­ ë“œë¼ì´ë²„ ë¦¬ìŠ¤íŠ¸ (ì¢…ë£Œ ì‹œ ì •ë¦¬ìš©)
_active_drivers = []

def cleanup_drivers():
    """í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì‹œ ëª¨ë“  ë“œë¼ì´ë²„ ì •ë¦¬"""
    global _active_drivers
    for driver in _active_drivers:
        try:
            if driver:
                safe_quit_driver(driver)
        except:
            pass
    _active_drivers.clear()

# í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì‹œ ìë™ ì •ë¦¬ ë“±ë¡
atexit.register(cleanup_drivers)

def safe_quit_driver(driver):
    """ë“œë¼ì´ë²„ë¥¼ ì•ˆì „í•˜ê²Œ ì¢…ë£Œ"""
    if not driver:
        return
    
    try:
        # ëª¨ë“  ì°½ ë‹«ê¸°
        for handle in driver.window_handles:
            driver.switch_to.window(handle)
            driver.close()
    except:
        pass
    
    try:
        driver.quit()
    except:
        pass
    
    # ì„œë¹„ìŠ¤ í”„ë¡œì„¸ìŠ¤ ì •ë¦¬
    try:
        if hasattr(driver, 'service') and driver.service:
            driver.service.stop()
    except:
        pass

@contextmanager
def setup_driver():
    """ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €ë¡œ ë“œë¼ì´ë²„ ê´€ë¦¬"""
    driver = None
    global _active_drivers
    
    try:
        options = uc.ChromeOptions()
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--start-maximized')
        options.add_argument('--disable-blink-features=AutomationControlled')
        options.add_argument('--disable-logging')
        options.add_argument('--disable-gpu-logging')
        options.add_argument('--log-level=3')
        options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36")
        
        driver = uc.Chrome(options=options)
        _active_drivers.append(driver)
        print("âœ… Chrome ë“œë¼ì´ë²„ê°€ ì„±ê³µì ìœ¼ë¡œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        yield driver
        
    except Exception as e:
        print(f"âŒ ë“œë¼ì´ë²„ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        yield None
    finally:
        if driver:
            try:
                # í™œì„± ë“œë¼ì´ë²„ ëª©ë¡ì—ì„œ ì œê±°
                if driver in _active_drivers:
                    _active_drivers.remove(driver)
                safe_quit_driver(driver)
                print("âœ… Chrome ë“œë¼ì´ë²„ê°€ ì•ˆì „í•˜ê²Œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                print(f"âš ï¸ ë“œë¼ì´ë²„ ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œ ê°€ëŠ¥): {e}")

def save_to_excel(reviews, filename="coupang_reviews.xlsx"):
    wb = Workbook()
    ws = wb.active
    ws.append(["ì‘ì„±ì", "ì‘ì„±ì¼", "í‰ì ", "ë¦¬ë·° ë‚´ìš©"])
    for r in reviews:
        ws.append([r["ì‘ì„±ì"], r["ì‘ì„±ì¼"], r["í‰ì "], r["ë¦¬ë·°ë‚´ìš©"]])
    wb.save(filename)
    print(f"âœ… ë¦¬ë·° ë°ì´í„°ê°€ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
def get_review_totalcount(driver):        
    try:
        review_count_element = WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.XPATH, '//a[contains(text(), "ìƒí’ˆí‰")]'))
        )
        text = review_count_element.text
        match = re.search(r'([\d,]+)', text)
        total_reviews = int(match.group(1).replace(',', '')) if match else 0
        return total_reviews
    except:
        return 0
    
def click_next_page(driver, current_page):
    try:
        old_usernames = [
            e.text for e in driver.find_elements(By.CSS_SELECTOR, 'span.sdp-review__article__list__info__user__name')
        ]
    except:
        old_usernames = []
    
    try:
        next_page_btn = WebDriverWait(driver, 5).until(
            EC.element_to_be_clickable((By.CSS_SELECTOR, f'button.js_reviewArticlePageBtn[data-page="{current_page + 1}"]'))
        )
        driver.execute_script("arguments[0].click();", next_page_btn)
        current_page += 1
        time.sleep(1.5)

        # í˜ì´ì§€ ë³€ê²½ í™•ì¸
        WebDriverWait(driver, 5).until(
            lambda d: any(
                e.text not in old_usernames 
                for e in d.find_elements(By.CSS_SELECTOR, 'span.sdp-review__article__list__info__user__name')
            )
        )
    except:
        try:
            # ë‹¤ìŒ ë¬¶ìŒìœ¼ë¡œ ë„˜ê¸°ê¸° (â–¶ ë²„íŠ¼)
            next_group_btn = WebDriverWait(driver, 5).until(
                EC.element_to_be_clickable((By.CSS_SELECTOR, 'button.sdp-review__article__page__next'))
            )
            driver.execute_script("arguments[0].click();", next_group_btn)
            time.sleep(1.5)

            next_page_btn = WebDriverWait(driver, 5).until(
                EC.element_to_be_clickable((By.CSS_SELECTOR, f'button.js_reviewArticlePageBtn[data-page="{current_page + 1}"]'))
            )
            driver.execute_script("arguments[0].click();", next_page_btn)
            current_page += 1
            time.sleep(1.5)

            WebDriverWait(driver, 5).until(
                lambda d: any(
                    e.text not in old_usernames 
                    for e in d.find_elements(By.CSS_SELECTOR, 'span.sdp-review__article__list__info__user__name')
                )
            )
        except:
            current_page += 1  # ì‹¤íŒ¨í•´ë„ ë¬´í•œë£¨í”„ ë°©ì§€ìš© ê°•ì œ ì¦ê°€
    
    return current_page

def crawl_reviews(url, driver):
    
    reviews = []
    
    try:
        print(f"ğŸ”„ URL ì ‘ì† ì¤‘: {url}")
        options = uc.ChromeOptions()
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--start-maximized')
        options.add_argument('--disable-blink-features=AutomationControlled')
        options.add_argument('--disable-logging')
        options.add_argument('--disable-gpu-logging')
        options.add_argument('--log-level=3')
        options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36")
        driver = uc.Chrome(options=options)
    
        driver.get(url)
        time.sleep(3)
        
        try:
            WebDriverWait(driver, 15).until(
                EC.element_to_be_clickable((By.XPATH, '//a[contains(text(), "ìƒí’ˆí‰")]'))
            ).click()
            time.sleep(3)
            print("âœ… ìƒí’ˆí‰ íƒ­ í´ë¦­ ì™„ë£Œ")
        except UnexpectedAlertPresentException:
            try:
                alert = driver.switch_to.alert
                print("âŒ ì¿ íŒ¡ì—ì„œ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. Alert ë©”ì‹œì§€:", alert.text)
                alert.accept()
            except:
                pass
            return []
        except Exception as e:
            print(f"âŒ ë¦¬ë·° íƒ­ ì§„ì… ì‹¤íŒ¨: {e}")
            return []

        try:
            total_review_count = get_review_totalcount(driver)
            total_pages = math.ceil(total_review_count / 10)
            current_page = 1
            
            print(f"ğŸ“Š ì´ ë¦¬ë·° ìˆ˜: {total_review_count}, ì´ í˜ì´ì§€ ìˆ˜: {total_pages}")
            
            # ìµœëŒ€ 50í˜ì´ì§€ë¡œ ì œí•œ (ë„ˆë¬´ ë§ì€ í˜ì´ì§€ ë°©ì§€)
            max_pages = min(total_pages, 50)
            
            for page in range(1, max_pages + 1):
                try:
                    articles = WebDriverWait(driver, 15).until(
                        EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'article.sdp-review__article__list'))
                    )
                    print(f"ğŸ“„ í˜ì´ì§€ {page}ì—ì„œ {len(articles)}ê°œ ë¦¬ë·° ë°œê²¬")
                except:
                    print(f"âš ï¸ í˜ì´ì§€ {page}ì—ì„œ ë¦¬ë·°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    continue

                page_reviews = 0
                for art in articles:
                    try:
                        username = art.find_element(By.CSS_SELECTOR, 'span.sdp-review__article__list__info__user__name').text
                    except NoSuchElementException:
                        username = ""

                    try:
                        date = art.find_element(By.CSS_SELECTOR, 'div.sdp-review__article__list__info__product-info__reg-date').text
                    except NoSuchElementException:
                        date = ""

                    try:
                        content = art.find_element(By.CSS_SELECTOR, 'div.sdp-review__article__list__review > div').text
                        content = re.sub(r"[\n\t]", "", content.strip())
                    except NoSuchElementException:
                        content = ""

                    try:
                        rating = int(art.find_element(By.CSS_SELECTOR, 'div.sdp-review__article__list__info__product-info__star-orange').get_attribute('data-rating'))
                    except (NoSuchElementException, ValueError, TypeError):
                        rating = 0

                    reviews.append({
                        "ì‘ì„±ì": username,
                        "ì‘ì„±ì¼": date,
                        "í‰ì ": rating,
                        "ë¦¬ë·°ë‚´ìš©": re.sub(r"[\n\t]", "", content.strip())
                    })
                    page_reviews += 1
                
                print(f"ğŸ“„ í˜ì´ì§€ {current_page} ì™„ë£Œ - ì´ë²ˆ í˜ì´ì§€: {page_reviews}ê°œ, ì´ ìˆ˜ì§‘: {len(reviews)}ê°œ")
                
                # ë§ˆì§€ë§‰ í˜ì´ì§€ê°€ ì•„ë‹ˆë©´ ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™
                if page < max_pages:
                    try:
                        current_page = click_next_page(driver, current_page)
                        time.sleep(2)  # í˜ì´ì§€ ì´ë™ í›„ ëŒ€ê¸°
                    except Exception as e:
                        print(f"âš ï¸ ë‹¤ìŒ í˜ì´ì§€ ì´ë™ ì‹¤íŒ¨: {e}")
                        break
                        
        except Exception as e:
            print(f"âŒ ë¦¬ë·° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            
    except Exception as e:
        print(f"âŒ ì „ì²´ í¬ë¡¤ë§ ê³¼ì •ì—ì„œ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    return reviews

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        url = input("í¬ë¡¤ë§í•  ì¿ íŒ¡ ìƒí’ˆ URLì„ ì…ë ¥í•˜ì„¸ìš”:\n").strip()
        
        if "coupang.com" not in url:
            print("âŒ ìœ íš¨í•œ ì¿ íŒ¡ ìƒí’ˆ URLì´ ì•„ë‹™ë‹ˆë‹¤.")
            return
        
        with setup_driver() as driver:
            if driver:
                review_data = crawl_reviews(url, driver)
                
                if review_data:
                    print(f"ğŸ‰ ì´ {len(review_data)}ê°œì˜ ë¦¬ë·°ë¥¼ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤!")
                    save_to_excel(review_data)
                else:
                    print("âŒ ìˆ˜ì§‘ëœ ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                print("âŒ ë“œë¼ì´ë²„ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                
    except KeyboardInterrupt:
        print("\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
    finally:
        cleanup_drivers()
        print("ğŸ”„ ëª¨ë“  ë¦¬ì†ŒìŠ¤ê°€ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()